--- 
knit: "bookdown::render_book"
---

```{r plot-distr, echo=FALSE}
grafico <- function (
  tabela,   # Um tibble com colunas X e p
  titulo,
  extra = NULL
) {
  
  g <- tabela %>% 
    ggplot() +
      geom_col(
        aes(x = X, y = p),
        width = .1, 
        fill = 'blue',
        color = 'blue'
      ) +
    labs(
      title = titulo,
      y = NULL
    )
  
  if (is.null(extra))
    g
  else
    g + extra
  
}
```


# Distribuições discretas {#discretas}

## Vídeo 1

```{r echo=FALSE, out.extra=center(), results='asis'}
embed_yt('jKSRgZdlTEM')
```


## Distribuição uniforme discreta

### Exemplo: um dado

* Cada resultado de $1$ a $6$ tem a mesma probabilidade de ocorrer.

* Variável aleatória $X$ 

* Suporte $\{ 1, 2,3 ,4 ,5 , 6 \}$

* Distribuição: $\text{Unif}(X \mid n=6)$:
  $$
  P(X = x) = \begin{cases}
        1/6 &\text{se } x \in \{1, 2, 3, 4, 5, 6\} \\
        0   &\text{senão}
      \end{cases}
  $$

### No geral

* $\text{Unif}(X = x \mid n)$

* $n \in \mathbb{N}^+$

* Distribuição: $\text{Unif}(X \mid n)$:
  $$
  P(X = x) = \begin{cases}
        1/n &\text{se } x \in \{1, \ldots, n\} \\
        0   &\text{senão}
      \end{cases}
  $$

* Valor esperado:
  $$
  \begin{align*}
  E(X) &= \frac{1}{n} \cdot (1 + \cdots + n)\\ 
       &= \frac{1}{n} \cdot \frac{n(n+1)}{2}\\ 
       &= \frac{n+1}{2}
  \end{align*}
  $$

* Variância:
$$
\begin{align}
\sigma^2(X) &= \sum \left[(x_i - \mu)^2 \cdot \frac1n \right]
                & \text{(definição de variância)}\\
            &= \frac1n \sum (x_i - \mu)^2 \\
            &= \frac1n \left[ \sum (x_i^2 -2\mu x_i + \mu^2) \right] \\
            &= \frac1n \left[ \sum x_i^2 - 2\mu \sum x_i + n\mu^2 \right] \\
            &= \frac1n \sum x_i^2 - 2\mu \frac{\sum x_i}{n} + \frac{n\mu^2}{n}  
                 & \left(\text{mas}\quad \frac{\sum x_i}{n} = \mu\right)\\
            &= \frac1n \sum x_i^2 - 2\mu^2 + \mu^2\\
            &= \frac1n \sum x_i^2 - \mu^2  
                & \left(\text{vamos usar a fórmula para } \sum x_i^2 \right)\\
            &= \frac1n \cdot \frac{n(n+1)(2n+1))}{6} - \mu^2  
                & \text{(vamos substituir } \mu \text{ pela fórmula)}\\
            &= \frac1n \cdot \frac{n(n+1)(2n+1))}{6} - \left(\frac{n+1}{2}\right)^2  
                & \text{(o resto é contarada)}\\
            &= (n+1) \left( \frac{2n+1}{6} - \frac{n+1}{4}\right) \\
            &= (n+1) \left( \frac{4n + 2 -3n - 3}{12}\right) \\
            &= \frac{(n+1)(n-1)}{12} \\
            &= \frac{n^2 - 1}{12}
\end{align}
$$

### Em R

::: {.rmdimportant}

As funções `dunif`, `punif`, `qunif` e `runif` trabalham com a distribuição uniforme *contínua*. Não servem para a distribuição uniforme *discreta*.

:::

* Para definir os valores possíveis da variável aleatória $X$, use um vetor.

```{r dado}
x <- 1:6
```

* Todas as probabilidades são iguais a $\frac1n$:

```{r probs-unif}
probs <- 1 / length(x)
```

* Distribuição:

```{r distr-unif-vetor}
distr <- tibble(
  X = x,
  p = probs
)

distr %>% gt()
```

* Exemplo: $P(X \leq 2)$:

```{r p-x-leq-3}
distr %>% 
  filter(X <=2) %>% 
  pull(p) %>% 
  sum()
```

* Gráfico:

```{r plot-uniforme, echo=FALSE}
grafico(
  distr, 
  paste('Uniforme de', 1, 'a', nrow(distr)), 
  scale_x_continuous(breaks = 1:nrow(distr))
)
```

* Para gerar amostras, use `sample`, que, por *default*, trabalha com a distribuição  uniforme discreta. Simulando dez lançamentos de um dado:

```{r sample-unif}
sample(1:6, size = 10, replace = TRUE)
```


## Distribuição de Bernoulli

### Exemplo: uma moeda

* Dois resultados possíveis: coroa ou cara.

* Variável aleatória
  $$
  X = \begin{cases}
        0 &\text{se coroa} \\
        1 &\text{se cara}
      \end{cases}
  $$
  
* Parâmetro: $p$ é a probabilidade de sucesso (cara).

* Distribuição: $\text{Bernoulli}(X \mid p = 0{,}5)$ para uma moeda justa:
  $$
  \begin{align*}
    P(X = 0) &= 1 - 0{,}5 \\
    P(X = 1) &= 0{,}5 
  \end{align*}
  $$
  também escrita como
  $$
    P(X = x) = 0{,}5^x \cdot (1 - 0{,}5)^{1 - x}
  $$

* Cada valor do parâmetro $p$ dá uma distribuição diferente.

* Gráfico com um valor específico de $p$:

```{r bernoulli, echo=FALSE}
prob_sucesso <- .8

distr <- tibble(
  X = 0:1,
  p = c(1 - prob_sucesso, prob_sucesso)
)

grafico(
  distr, 
  paste('Bernoulli( X | p = ', prob_sucesso, ')'),
  scale_x_continuous(
      breaks = 0:1, 
      limits = c(-.5, 1.5)
  )
)

```
  
### No geral

* $\text{Bernoulli}(X = x \mid p)$

* $x \in \{0, 1\}$

* $p \in [0, 1]$

* Valor esperado:
$$
\begin{align*}
E(X) &= 0 \cdot (1 - p) \;+\: 1 \cdot p \\
     &= p
\end{align*}
$$

* Variância:
$$
\begin{align*}
\sigma^2(X) &= (0 - p)^2 \cdot (1 - p) \;+\: (1 - p)^2 \cdot p \\
     &= p^2 - p^3 + p - 2p^2 + p^3 \\
     &= -p^2 + p \\
     &= p(1 - p)
\end{align*}
$$

### Em R

::: {.rmdimportant}

A distribuição de Bernoulli é um caso especial ($n = 1$) da distribuição *binomial*, que nós vamos ver abaixo.

:::

* Se você não quiser usar a distribuição binomial, pode usar um vetor de valores e um vetor de probabilidades (ambos de tamanho $2$), e usar `sample` com o argumento `prob`. 

* Por exemplo, para simular $10$ lançamentos de uma moeda viciada:

```{r moeda-viciada}
moeda <- 0:1
probs <- c(.2, .8)
sample(moeda, size = 10, prob = probs, replace = TRUE)
```

## Distribuição geométrica

### Exemplo: *spam*

* Cada e-mail tem probabilidade $0{,}1$ de não ser *spam*, e $0{,}9$ de ser *spam*. 

* Considere que cada e-mail é *independente* de cada outro.

* Você abre sua *inbox* (sem filtro *antispam*) e começa a abrir as mensagens sequencialmente.

* A variável aleatória $X$ é o número de mensagens *spam* que você precisa abrir até chegar à primeira mensagem que não é *spam*.

* Suporte $\{0, 1, 2, 3, \ldots \}$

* Parâmetro: $p$ é a probabilidade de sucesso (não *spam*).

* Distribuição: $\text{Geom}(X \mid p = 0{,}1)$.

* Qual a probabilidade de que a primeira mensagem não-*spam* seja a décima? 

$$
\begin{align*}
\text{Geom}(X = 9 \mid p = 0{,}1)  &= 0{,}9^9 \cdot 0{,}1 \\
                        &\approx 0{,}39 
\end{align*}
$$

* Gráfico:

```{r geom-plot, echo=FALSE}
p_nao_spam <- .1
x <- 0:50

spam <- tibble(
  X = x,
  p = dgeom(X, p_nao_spam)
)

grafico(spam, paste('Geom( X | p = ', p_nao_spam, ')'))
```


### No geral

* $X$ conta a quantidade de *provas de Bernoulli* que têm resultado fracasso antes do primeiro sucesso.

* As provas de Bernoulli são independentes e têm probabilidade fixa de sucesso $p$.

* $\text{Geom}(X = x \mid p) = (1-p)^x \cdot p$

* $x \in \{0, 1, 2, \ldots\}$

* Valor esperado:

  Vamos chamar $1 - p$ de $q$. Então, $P(X = x) = q^x \cdot p$. Daí,
  
  $$
  \begin{align*}
  E(X) &= 0p + 1qp + 2q^2p + 3q^3p + \cdots \\
       &= 0(1-q) + 1q(1-q) + 2q^2(1-q) + 3q^3(1-q) + \cdots \\
       &= q - q^2 + 2q^2 - 2q^3 + 3q^3 - 3q^4 + \cdots \\
       &= q + q^2 + q^3 + \cdots \\
       &= \frac{q}{1-q} \\
       &= \frac{1-p}{p}
  \end{align*}
  $$

  No exemplo dos e-mails, $E(X) = \frac{1-p}{p} = \frac{0{,}9}{0{,}1} = `r 0.9/0.1`$.
  
* Variância:

  $$
  \sigma^2(X) = \frac{1-p}{p^2}
  $$


### Em R

#### Função de distribuição de probabilidade: $\text{Geom}(X = x \mid p)$ 

```{r grafico-dgeom, echo=FALSE}
x <- 0:20
p_sucesso <- .1

tabela <- tibble(
  X = x,
  p = dgeom(X, p_sucesso)
)

grafico(tabela, paste('Geom( X | p = ', p_sucesso, ')')) +
  geom_col(
    data = tabela %>% filter(X == 9),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste('Em vermelho, dgeom(9, 0.1) =', dgeom(9, .1) %>% round(3))
  )
  
  
```

* `dgeom(x, prob)`

* Tanto `x` quanto `prob` podem ser vetores.

* No exemplo do *spam*, probabilidades de $X$ ser $0, 1, 2, \ldots, 10$:

```{r dgeom-1-a-10}
dgeom(x = 0:10, prob = .1)
```

* Se a probabilidade de *spam* for $0{,}1; 0{,}2; 0{,}3; \ldots; 0{,}9; 1{,}0$, qual a probabilidade de ter que abrir $10$ mensagens *spam* antes de chegar à primeira mensagem não-*spam*?

```{r dgeom-varios-p}
dgeom(10, prob = seq(0.1, 1.0, 0.1))
```

* Mas cuidado: se os dois argumentos forem vetores, o resultado é um vetor com o comprimento do maior argumento, com os valores de `x` pareados um a um com os valores de `prob` (lembrando que R recicla o vetor mais curto):

```{r dgeom-dois-vetores}
dgeom(c(10, 11, 12), c(0.1, 0.2))
```
Os valores acima são, respectivamente, $P(X = 10 \mid p = 0{,}1)$, $P(X = 11 \mid p = 0{,}2)$ e $P(X = 12 \mid p = 0{,}1)$.

#### Função de distribuição acumulada: $\text{Geom}(X \leq q \mid p)$

```{r grafico-pgeom, echo=FALSE}
x <- 0:20
p_sucesso <- .1

tabela <- tibble(
  X = x,
  p = dgeom(X, p_sucesso)
)

grafico(tabela, paste('Geom( X | p = ', p_sucesso, ')')) +
  geom_col(
    data = tabela %>% filter(X <= 9),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste('Em vermelho, pgeom(9, 0.1) =', pgeom(9, .1) %>% round(3))
  )
  
  
```

* `pgeom(q, prob, lower.tail = TRUE)`

* Se você passar `lower.tail = FALSE`, a probabilidade calculada é $P(X > q \mid \text{prob})$.

```{r grafico-pgeom-upper, echo=FALSE}
x <- 0:20
p_sucesso <- .1

tabela <- tibble(
  X = x,
  p = dgeom(X, p_sucesso)
)

grafico(tabela, paste('Geom( X | p = ', p_sucesso, ')')) +
  geom_col(
    data = tabela %>% filter(X > 9),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'Em vermelho, pgeom(9, 0.1, lower.tail = FALSE) =', 
      pgeom(9, .1, lower.tail = FALSE) %>% round(3))
  )
  
  
```

* Tanto `q` quanto `prob` podem ser vetores.

* No exemplo do *spam*, a probabilidade de precisar abrir *no máximo* $10$ mensagens *spam* para então abrir a primeira mensagem não-*spam* é

  ```{r geom-leq-10}
  pgeom(q = 10, prob = .1)
  ```

  que, na verdade, é o mesmo que somar as probabilidades de $X = 0$, $X = 1$, etc., até $X = 10$:
  
  ```{r geom-sum-10}
  sum(dgeom(0:10, .1))
  ```
  
* Um exemplo mais realista: cada vez que você joga $6$ números na Mega-Sena, a probabilidade de você acertar a sena é de $1$ em $50.063.860$, segundo http://loterias.caixa.gov.br/wps/portal/loterias/landing/megasena. 

  Qual a probabilidade de você acertar a sena em alguma das primeiras $1.000$ vezes que você jogar? $10.000$ vezes? $100.000$ vezes (o que equivale a $`r round((1e5 / 2) / 52, 1) %>% fm()`$ anos, jogando $2$ vezes por semana)?

  ```{r loteria}
  p <- 1/50063860
  pgeom(c(1e3, 1e4, 1e5), p)
  ```

  Qual a probabilidade de você jogar duas vezes por semana, durante $100$ anos, sem acertar a sena? Considerando $52$ semanas por ano:

  ```{r loteria2}
  vezes <- 2 * 52 * 100
  vezes
  pgeom(vezes, p, lower.tail = FALSE)
  ```
  
  O problema é que, com uma probabilidade de sucesso tão baixa, a distribuição geométrica começa em um valor baixo e decresce muito lentamente. O gráfico abaixo vai até $X = 1$ milhão. A área da faixa vermelha é a probabilidade de você acertar a sena jogando no máximo $10$ mil vezes. Esta probabilidade é $`r pgeom(1e4, p) %>% fm()`$. 
  
  Isto equivale a dizer que a probabilidade de você precisar de mais de $10$ mil jogos para acertar a sena é de $1 - `r pgeom(1e4, p) %>% fm()` = `r fm(1 - pgeom(1e4, p))`$, que é a área em azul no gráfico, *mais a área restante à direita, de $1$ milhão até o infinito*, que não aparece no gráfico!
  
```{r loteria-plot , echo=FALSE}
x <- seq(0, vezes*100, 1000)
p_sucesso <- p

tabela <- tibble(
  X = x,
  p = dgeom(X, p_sucesso)
)

grafico(tabela, paste('Geom( X | p = ', p_sucesso, ')')) +
  geom_col(
    data = tabela %>% filter(X <= 10000),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  scale_x_continuous(labels = fm)
```
  

#### Função quantil: dado um valor de $\text{Geom}(X \leq x \mid p)$, então $x = ?$

```{r grafico-qgeom, echo=FALSE}
x <- 0:20
p_sucesso <- .1

tabela <- tibble(
  X = x,
  p = dgeom(X, p_sucesso)
)

grafico(tabela, paste('Geom( X | p = ', p_sucesso, ')')) +
  geom_col(
    data = tabela %>% filter(X <= 9),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'A área em vermelho é', 
      pgeom(9, 0.1) %>% round(3)
    )
  ) +
  geom_text(
    mapping = aes(9, -.01, label = 'qgeom(0.651, 0.1) = 9'),
    color = 'red',
    size = 5
  ) +
  geom_segment(
    mapping = aes(
      x = 9, 
      y = -.005, 
      xend = 9, 
      yend = -.001
    ),
    color = 'red'
  )
  
  
```

* `qgeom(p, prob, lower.tail = TRUE)`

* Se você passar `lower.tail = FALSE`, o quantil calculado é $q$ tal que $P(X > q \mid \text{prob}) = p$:

```{r grafico-qgeom2, echo=FALSE}
x <- 0:20
p_sucesso <- .1

tabela <- tibble(
  X = x,
  p = dgeom(X, p_sucesso)
)

grafico(tabela, paste('Geom( X | p = ', p_sucesso, ')')) +
  geom_col(
    data = tabela %>% filter(X > 9),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'A área em vermelho é', 
      pgeom(9, 0.1, lower.tail = FALSE) %>% round(3)
    )
  ) +
  geom_text(
    mapping = aes(9, -.01, label = 'qgeom(0.349, 0.1, lower.tail = FALSE) = 9'),
    color = 'red',
    size = 5
  ) +
  geom_segment(
    mapping = aes(
      x = 9, 
      y = -.005, 
      xend = 9, 
      yend = -.001
    ),
    color = 'red'
  )
  
  
```

* Quantas vezes você precisa apostar $6$ números na Mega-Sena para ter $50$% de chance de acertar a sena alguma vez?

```{r quantas-megasena}
p <- 1/50063860
qgeom(.5, p)
```

* Isto equivale a $`r round(qgeom(.5, p) / (2 * 52)) %>% fm()`$ anos, jogando duas vezes por semana, toda semana.

#### Geração de números aleatórios

* `rgeom(n, prob)` retorna um vetor de `n` valores sorteados de uma distribuição $\text{Geom}(X \mid \text{prob})$.

* Voltando ao exemplo do *spam*. Vamos simular muitos experimentos. Os resultados são os valores de $X$, i.e., as quantidades de mensagens *spam* que precisaram ser abertas antes de chegar à primeira mensagem não-spam:

```{r spam-sim}
amostra <- rgeom(1000, .1)
head(amostra)
```

* O valor esperado é $\frac{1-p}{p} = 9$. Vamos comparar com a média da amostra gerada:

```{r e-spam}
mean(amostra)
```

* A variância é $\frac{1-p}{p^2} = `r .9 / .1^2`$. Vamos comparar com a variância da amostra:

```{r v-spam}
var(amostra)
```


* Vamos simular $100$ mil pessoas jogando na Mega-Sena e ver se alguma acertou a sena antes de jogar mil vezes:

```{r megasena-sim}
p <- 1/50063860
resultados <- rgeom(1e5, p)
resultados[resultados <= 1e3]
```

* Qual a média da nossa amostra? O valor esperado é $`r fm((1 - p) / p)`$.

```{r e-megasena}
mean(resultados)
```

* E a mediana?

```{r mediana-megasena}
median(resultados)
```

* E o máximo?

```{r max-megasena}
max(resultados)
```

* E o mínimo?

```{r min-megasena}
min(resultados)
```

* Gráfico da nossa amostra:

```{r megasena-amostra-plot, echo=FALSE}
resultados %>% 
  as_tibble() %>% 
  ggplot() +
    geom_histogram(aes(x = value), binwidth = 1e6) +
    labs(
      title = 'Simulação: 100 mil pessoas jogando na Mega-Sena',
      x = 'Qtde de jogos até acertar a sena',
      y = 'Pessoas'
    )
```

* Os sortudos:

```{r megasena-amostra-plot-sortudos, echo=FALSE}
resultados %>% 
  as_tibble() %>% 
  filter(value <= 1e4) %>% 
  ggplot() +
    geom_histogram(aes(x = value), breaks = seq(0, 1e4, 1e3)) +
    labs(
      title = 'Simulação: 100 mil pessoas jogando na Mega-Sena',
      subtitle = 'mostrando só os que acertaram a sena em 10 mil tentativas ou menos',
      x = 'Qtde de jogos até acertar a sena',
      y = 'Pessoas'
    )
```


## Vídeo 2

```{r echo=FALSE, out.extra=center(), results='asis'}
embed_yt('F6OEoEaYrCw')
```


## Distribuição binomial

### Exemplo: *spam* novamente

* Vamos mudar para um mundo onde a probabilidade de uma mensagem qualquer *não* ser *spam* é $p = 0{,}3$ .

* Agora, vamos mudar o experimento: ao recebermos $n = 10$ mensagens, quantas não são *spam*?

* A variável aleatória $X$ é o número de sucessos (não *spam*) em $n = 10$ mensagens.

* Suporte $\{ 0, 1, 2, \ldots, 10 \}$

* Parâmetros:

  * $p$ é a probabilidade de sucesso (não *spam*).
  
  * $n$ é o número total de mensagens.
  
* Distribuição: $\text{Binom}(X \mid n = 10, p = 0{,}3)$.

* Qual a probabilidade de haver $4$ mensagens não *spam*? As mensagens são independentes. O resultado vai envolver:

  * A probabilidade de $4$ mensagens não serem *spam*: $(0{,}3)^4$.
  
  * A probabilidade de $6$ mensagens serem *spam*: $(1 - 0{,}3)^6$.
  
  * A quantidade de ordenações diferentes destas $10$ mensagens: ${10 \choose 4} = \frac{10!}{4!6!} = `r choose(10, 4)`$. 

  * O resultado é

$$
\begin{align*}
\text{Binom}(X = 5 \mid n = 10,\; p = 0{,}3) 
  &= {10 \choose 4} \cdot (0{,}3)^4 \cdot (1 - 0{,}3)^6 \\
  &= `r dbinom(4, 10, 0.3) %>% fm()`
\end{align*}
$$

* Gráfico:

```{r binom-plot, echo=FALSE}
p_nao_spam <- .3
size <- 10
x <- 0:size

spam <- tibble(
  X = x,
  p = dbinom(X, size, p_nao_spam)
)

grafico(
  spam, 
  paste0('Binom( X | n = ', size, ', p = ', p_nao_spam, ')'),
  scale_x_continuous(breaks = 0:10)
)
```

### No geral

* $X$ conta a quantidade de sucessos em um número fixo $n$ de provas de Bernoulli.

* As provas de Bernoulli são independentes e têm probabilidade fixa de sucesso $p$.

* $\text{Binom}(X = x \mid n, p) = {n \choose x} \cdot p^x \cdot (1 - p)^{n - x}$

* $x \in \{ 0, 1, 2, \ldots, n\}$

* Valor esperado:

  * Na verdade, $X$ é a soma de $n$ variáveis aleatórias independentes $X_1, \ldots, X_n$, cada uma delas com distribuição de Bernoulli com probabilidade de sucesso $p$ (e valor esperado $p$):
  
$$
  \begin{align*}
    E(X) &= E(X_1 + \cdots + X_n) \\ 
         &= E(X_1) + \cdots + E(X_n) \\
         &= p + \cdots + p \\
         &= np
  \end{align*}
$$
  
* Variância:

  * Como as variáveis $X_1, \ldots, X_n$ são independentes, a variância da soma é a soma das variâncias:

$$
  \begin{align*}
    \sigma^2(X) &= \sigma^2(X_1 + \cdots + X_n) \\ 
         &= \sigma^2(X_1) + \cdots + \sigma^2(X_n) \\
         &= p(1-p) + \cdots + p(1-p) \\
         &= np(1-p)
  \end{align*}
$$


### Em R

#### Função de distribuição de probabilidade: $\text{Binom}(X = x \mid n, p)$ 

```{r grafico-dbinom, echo=FALSE}
n <- 10
x <- 0:n
p_sucesso <- .3

tabela <- tibble(
  X = x,
  p = dbinom(X, n, p_sucesso)
)

grafico(
  tabela, 
  paste0('Binom( X | n = ', n, ', p = ', p_sucesso, ' )'),
  scale_x_continuous(breaks = 0:10)
) +
  geom_col(
    data = tabela %>% filter(X == 4),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'Em vermelho, dbinom(4, 10, 0.3) =', 
      dbinom(4, n, p_sucesso) %>% round(3)
    )
  )
```

* `dbinom(x, size, prob)`

* Voltando à Mega-Sena: para uma única pessoa, jogar é uma prova de Bernoulli, com probabilidade de sucesso de $1/50.063.860 = `r 1/50063860`$. Se você jogar $6$ números $10$ mil vezes --- duas vezes por semana, durante quase $100$ anos --- sua probabilidade de ganhar pelo menos uma vez é

```{r sena-binom}
p <- 1/50063860
vezes <- 1e4
pbinom(1, vezes, p, lower.tail = FALSE)
```

* O gráfico desta distribuição é

```{r grafico-sena-binom, echo=FALSE}
n <- 1e4
x <- 0:n
p_sucesso <- 1/50063860

tabela <- tibble(
  X = x,
  p = dbinom(X, n, p_sucesso)
)

grafico(
  tabela, 
  paste0('Binom( X | n = ', fm(n), ', p = ', p_sucesso, ' )')
) 

```

* A probabilidade de jogar $10$ mil vezes e obter zero sucessos é

```{r zero-sucessos}
dbinom(0, n, p_sucesso)
```



#### Função de distribuição acumulada: $\text{Binom}(X \leq q \mid n, p)$

```{r grafico-pbinom, echo=FALSE}
n <- 10
x <- 0:n
p_sucesso <- .3

tabela <- tibble(
  X = x,
  p = dbinom(X, n, p_sucesso)
)

grafico(
  tabela, 
  paste0('Binom( X | n = ', n, ', p = ', p_sucesso, ' )'),
  scale_x_continuous(breaks = 0:10)
) +
  geom_col(
    data = tabela %>% filter(X <= 4),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'Em vermelho, pbinom(4, 10, 0.3) =', 
      pbinom(4, n, p_sucesso) %>% round(3)
    )
  )
```

* `pbinom(q, size, prob, lower.tail = TRUE)`

* Se você passar `lower.tail = FALSE`, a probabilidade calculada é $P(X>q \mid \text{size}, \text{prob})$.

```{r grafico-pbinom-right, echo=FALSE}
n <- 10
x <- 0:n
p_sucesso <- .3

tabela <- tibble(
  X = x,
  p = dbinom(X, n, p_sucesso)
)

grafico(
  tabela, 
  paste0('Binom( X | n = ', n, ', p = ', p_sucesso, ' )'),
  scale_x_continuous(breaks = 0:10)
) +
  geom_col(
    data = tabela %>% filter(X > 4),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'Em vermelho, pbinom(4, 0.3, lower.tail = FALSE) =', 
      pbinom(4, n, p_sucesso, lower.tail = FALSE ) %>% round(3)
    )
  )
```

#### Função quantil: dado um valor de $\text{Binom}(X \leq x \mid n, p)$, então $x = ?$

```{r grafico-qbinom, echo=FALSE}
n <- 10
x <- 0:n
p_sucesso <- .3

tabela <- tibble(
  X = x,
  p = dbinom(X, n, p_sucesso)
)

grafico(
  tabela, 
  paste0('Binom( X | n = ', n, ', p = ', p_sucesso, ' )'),
  scale_x_continuous(breaks = 0:10)
) +
  geom_col(
    data = tabela %>% filter(X <= 4),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'A área em vermelho é', 
      pbinom(4, n, p_sucesso) %>% round(3)
    )
  ) +
  geom_text(
    mapping = aes(4, -.04, label = 'qbinom(0.85, 10, 0.3) = 4'),
    color = 'red',
    size = 5
  ) +
  geom_segment(
    mapping = aes(
      x = 4, 
      y = -.005, 
      xend = 4, 
      yend = -.025
    ),
    color = 'red'
  )

```

* `qbinom(p, size, prob)`

* Se você passar `lower.tail = FALSE`, o quantil calculado é $q$ tal que $P(X > q \mid \text{size}, \text{prob}) = p$:

```{r grafico-qbinom-right, echo=FALSE}
n <- 10
x <- 0:n
p_sucesso <- .3

tabela <- tibble(
  X = x,
  p = dbinom(X, n, p_sucesso)
)

grafico(
  tabela, 
  paste0('Binom( X | n = ', n, ', p = ', p_sucesso, ' )'),
  scale_x_continuous(breaks = 0:10)
) +
  geom_col(
    data = tabela %>% filter(X > 4),
    aes(X, p),
    color = 'red',
    fill = 'red',
    width = .1
  ) +
  labs(
    subtitle = paste(
      'A área em vermelho é', 
      pbinom(4, n, p_sucesso, lower.tail = FALSE) %>% round(3)
    )
  ) +
  geom_text(
    mapping = aes(4, -.04, label = 'qbinom(0.15, 10, 0.3, lower.tail = FALSE) = 4'),
    color = 'red',
    size = 5
  ) +
  geom_segment(
    mapping = aes(
      x = 4, 
      y = -.005, 
      xend = 4, 
      yend = -.025
    ),
    color = 'red'
  )

```

#### Geração de números aleatórios

* `rbinom(n, size, prob)` retorna um vetor de `n` valores sorteados de uma distribuição $\text{Binom}(X \mid \text{size}, \text{prob})$.

* Vamos simular $100$ vezes o experimento de abrir $10$ mensagens e contar quantas delas não são *spam*:

```{r spam-sim-binom}
amostra <- rbinom(100, 10, .3)
amostra
```

* Média:

```{r media-spam-binom}
mean(amostra)
```

* Finalmente, vamos simular $100$ mil pessoas, cada uma jogando $10$ mil jogos da Mega-Sena e ver quantas ganharam pelo menos uma vez:

```{r sena-sim-binom}
n <- 1e5
p <- 1/50063860
size <- 1e4

resultados <- rbinom(n, size, p)
head(resultados, 1000)
```

```{r alguem-ganhou}
ganhadores <- resultados[resultados > 0]
ganhadores
length(ganhadores)
```


## Distribuição de Poisson

### Exemplo

* Em um caixa de um pequeno mercado, o número de clientes que chegam por minuto é, em média, $4$. 

* Vamos representar este número pela variável aleatória $X$, com suporte $\{ 0, 1, 2, 3, \ldots \}$.

* As chegadas dos clientes são independentes umas das outras.

* Se você dividir o tempo em intervalos menores do que um minuto, a média se mantém: $2$ clientes a cada $30$ segundos, $1$ cliente a cada $15$ segundos etc.

* Clientes diferentes não chegam ao caixa no mesmo instante.

* Com estas condições, e chamando o número médio de $\lambda = 4$, a probabilidade de que $10$ clientes cheguem ao caixa em um período de um minuto é dada por

$$
\begin{align*}
P(X = 10) &= \text{Poisson}(X = 10 \mid \lambda = 4) \\
          &= \frac{\lambda^{10}}{10!}e^{-\lambda} \\
          &= \frac{4^{10}}{10!}e^{-4} \\
          &= `r dpois(10, 4) %>% fm()`
\end{align*}
$$

* A probabilidade de que o caixa fique vazio durante um minuto inteiro é

$$
\begin{align*}
P(X = 10) &= \text{Poisson}(X = 0 \mid \lambda = 4) \\
          &= \frac{\lambda^{0}}{0!}e^{-\lambda} \\
          &= \frac{4^{0}}{0!}e^{-4} \\
          &= `r dpois(0, 4) %>% fm()`
\end{align*}
$$

* O gráfico (até $X = 20$) é

```{r pois-mercado, echo=FALSE}
x <- 0:20
lambda <- 4

tabela <- tibble(
  X = x,
  p = dpois(X, lambda)
)

tabela %>% 
  grafico(
    'Poisson( X | λ = 4 )'
  )
```


### No geral

* A distribuição de Poisson é um bom modelo para situações em que a variável aleatória $X$ conta o número de ocorrências de algum fenômeno em um intervalo de tempo fixo (ou em uma área ou volume de espaço): 

  * Carros passando em um cruzamento em uma hora,
  
  * Chamadas telefônicas chegando por minuto a uma central,
  
  * Partículas alfa emitidas por minuto por $1$Kg de um material radioativo,
  
  * Casos de uma doença detectados em cada Km$^2$ de uma cidade,
  
  * Erros de impressão por página em livros produzidos por uma editora.
  
* Teoricamente, $P(X=x)$ é maior que zero para qualquer $x$ natural; no mundo real, existem valores máximos que estas variáveis aleatórias podem assumir. Ainda assim, esta distribuição é uma boa aproximação. Por exemplo, a probabilidade de $40$ ou mais clientes chegarem ao nosso caixa de mercado em um minuto é de $`r ppois(39, 4, lower.tail = FALSE) %>% fm()`$.

* O valor esperado $E(X)$ e a variância $\sigma^2(X)$ são iguais a $\lambda$.

### Em R

#### Exercício

Seguindo o estilo das explicações sobre a [distribuição geométrica](#em-r-2) e a [distribuição binomial](#em-r-3):

1. Gere gráficos com exemplos do uso de `dpois`.

1. Gere gráficos com exemplos do uso de `ppois`.

1. Gere gráficos com exemplos do uso de `qpois`.

1. Faça uma simulação usando `rpois`. Detalhe o exemplo do nosso pequeno mercado, que atende $4$ clientes por minuto:

   a. Gere uma amostra de números correspondendo a $1$ hora de funcionamento do caixa.
   
   a. Escreva uma função em R para processar esta amostra e retornar um vetor com a quantidade de clientes na fila ao final de cada minuto (de $1$ a $60$). Lembre-se de que o caixa processa $4$ clientes por minuto.
   
   a. Agora gere uma amostra de números correspondendo a $1$ hora de funcionamento do caixa, com uma média de $5$ clientes chegando por minuto.
   
   a. Use a função que você escreveu para processar esta amostra e retornar um vetor com a quantidade de clientes na fila a cada minuto (de $1$ a $60$), *supondo que o caixa ainda processa só $4$ clientes por minuto*.
   

### Aproximação da Binomial pela Poisson

* Um fabricante de carros descobre que $1$ em cada $2.500$ carros que ele produz tem um defeito.

* Qual a probabilidade de achar $4$ carros com defeito em uma amostra de $6.000$ carros?

* Vamos usar $\text{Binom}\left(X \;\middle\vert\;n = 6.000, p = \frac{1}{2.500}\right)$:

```{r carros-binom}
prob <- 1/2500
size <- 6000
x <- 4
dbinom(x, size, prob)
```

* Mas, e se modelarmos o problema com Poisson em vez da Binomial?

* Uma das condições para usar Poisson é que a média seja constante. Para $6.000$ carros, a média de defeitos é $\frac{6.000}{2.500} = `r fm(6000/2500)`$.

* Vamos usar, então, $\text{Poisson}\left(X \;\middle\vert\; \lambda = `r fm(6000/2500)` \right)$:

```{r}
lambda <- 6000/2500
x <- 4
dpois(x, lambda)
```

* Gráfico:

```{r pois-binom-aprox, echo=FALSE}
x <- 0:10
tabela <- tibble(
  X = x,
  b = dbinom(X, size, prob),
  p = dpois(X, lambda)
)

tabela %>% 
  ggplot() +
    geom_point(
      aes(x = X, y = b, color = 'Binomial'),
      size = 4,
      alpha = .5
    ) +
    geom_point(
      aes(x = X, y = p, color = 'Poisson'),
      size = 1
    ) +
    scale_x_continuous(breaks = 0:10) +
    labs(
      title = 'Comparação:  Binom( X | n = 6.000, p = 1/2.500 )  e  Poisson( X | λ = 2,4 )',
      y = NULL,
      color = NULL
    )

```

* Para valores grandes de $n~(6.000)$ e pequenos de $p~(1/2.500)$, a Binomial pode ser aproximada pela Poisson --- desde que você calcule a média $\lambda$, como fizemos.

* A vantagem é que, diferente da Binomial, a Poisson não exige o cálculo do valor de $n \choose x$, que pode ser inviável mesmo com um computador.

::: {.rmdimportant latex=1}

Por quê?

O exemplo da quantidade de emissões de partículas alfa por minuto por uma massa fixa de material radioativo mostra uma relação fundamental entre as duas distribuições:

  * Do ponto de vista de Poisson, sabemos a média de emissões por minuto do material, sem levar em consideração o comportamento de cada átomo.
  
  * Do ponto de vista da Binomial, o material é composto por um número enorme de átomos ($n$ é grande!), cada átomo com uma probabilidade fixa e muito baixa ($p$ pequeno!) de emitir uma partícula alfa no período de um minuto.

:::


## Funções para distribuições em R

A esta altura, você já entendeu como funcionam as funções do R para distribuições discretas de probabilidade. Para uma distribuição de nome `DISTRIB`, as funções são as seguintes (`...` representam os parâmetros da distribuição):

* `dDISTRIB(x, ...)`: retorna a probabilidade $P(X = x)$.

* `pDISTRIB(q, ...)`: retorna a probabilidade $P(X \leq q)$ --- ou a probabilidade $P(X > q)$ se `lower.tail = FALSE`.

* `qDISTRIB(p, ...)`: retorna o maior valor $q$ tal que $P(X = q) \leq p$ --- ou o menor valor $q$ tal que $P(X = q) > p$ se `lower.tail = FALSE`.

* `rDISTRIB(n, ...)`: retorna um vetor com $n$ valores sorteados de acordo com a distribuição.


## Jardim zoológico de distribuições

Para sua diversão: https://ben18785.shinyapps.io/distribution-zoo/
